+++
title="大数据 实战（一）| hadoop 安装"
tags=["hadoop"]
categories=["大数据"]
date="2020-04-27T21:00:00+08:00"
+++
## 1.环境准备
### 1.1 服务器规划
```
# -u root -p centosdata 
172.16.232.130 centos701
172.16.232.131 centos702
172.16.232.132 centos703
```
### 1.2 关闭所有服务器的防火墙
```
systemctl stop firewalld.service # 停止firewall。
systemctl disable firewalld.service # 禁止firewall开机启动。
firewall-cmd --state # 查看默认防火墙装状态(关闭后显示notrunning, 开启显示running)。

ansible all -m shell -a 'firewall-cmd --state'
```
### 1.3 关闭服务器的SLNEX
```
vim /etc/selinux/config
SELINUX=disabled
```
### 1.4 配置时间同步
```
> yum install -y ntpdate
> crontab -e 
# 每分钟同步一次
*/1 * * * * /usr/sbin/ntpdate us.pool.ntp.org;

> date
```

### 1.5 安装网络工具net-tools
```
yum install -y net-tools
```

### 1.6 安装 java
```
rpm -ivh java-xxxx.rpm

/etc/profile  // 不建议配置在所有用户下
# java
export JAVA_HOME=/opt/jdk
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar

```
### 1.7 克隆虚拟机
```sh
# 关机重启
> init 0
```
#### 1.7.1 主机名和ip配置
```
172.16.232.130 centos701
172.16.232.131 centos702
172.16.232.132 centos703
```
#### 1.7.2 root用户免密码登录配置
1. 将centos701的公钥拷贝到centos702,centos703上
2. 将centos702的公钥拷贝到centos701,centos703上
3. 将centos703的公钥拷贝到centos701,centos702上

以下以centos701为例执行秘钥复制命令：ssh-copy-id -i 主机名
```
[root@centos701 ~]# ssh-copy-id -i centos702
[root@centos701 ~]# ssh-copy-id -i centos703
```

### 1.8 验证免密登录配置

此操作只在centos701上操作，其他机器上大家在验证。

```shell
#使用ssh 命令登录centos702
[root@centos701 ~]# ssh centos702
Last login: Sun Jun 30 13:56:53 2019 from centos701
#登录成功后这里的命令提示符已经变为[root@centos702 ~]#说明登录成功
[root@centos702 ~]# logout #退出centos702继续 验证登录centos703
Connection to centos702 closed.
#登录centos703
[root@centos701 ~]# ssh centos703
Last login: Sun Jun 30 13:56:55 2019 from centos701
#登录成功
[root@centos703 ~]# logout
Connection to centos703 closed.
You have new mail in /var/spool/mail/root
[root@centos701 ~]# 
```

### 1.9 添加本地认证公钥到认证文件中

```shell
#进入到root用户的家目录下
[root@centos701 ~]# cd ~
[root@centos701 ~]# cd .ssh/
#讲生成的公钥添加到认证文件中
[root@centos701 .ssh]# cat id_rsa.pub >> authorized_keys
[root@centos701 .ssh]# 
```

## 2.安装hadoop
- 存储和计算
- 批处理
- 流处理
### 2.1 hadoop解压后文件组织结构
- 下载地址：http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz
- tar -C /opt/ zxf hadoop-3.1.2.tar.gz
```
$ tree -L 1
├── bin
├── etc
├── include
├── lib
├── libexec
├── LICENSE.txt
├── logs
├── NOTICE.txt
├── README.txt
├── sbin
└── share
```
### 2.2 配置环境变量
```
# hadoop
export HADOOP_HOME=/opt/hadoop-3.1.2
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_COMMON_LIB_NATIVE_DIR"
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
### 2.3 创建hadoop 账户
- 创建hadoop用户组和hadoop用户需要在三台机器上分别操作
```
#1.创建用户组hadoop
[root@centos701 ~]# groupadd hadoop
#2.创建用户hadoop并添加到hadoop用户组中
[root@centos701 ~]# useradd -g hadoop hadoop
#3.使用id命令查看hadoop用户组和hadoop用户创建是否成功
[root@centos701 ~]# id hadoop
#用户uid 			用户组id gid      用户组名
uid=1000(hadoop) gid=1000(hadoop) groups=1000(hadoop)
#设置hadoop用户密码为hadoop
[root@centos701 ~]# passwd hadoop
Changing password for user hadoop.
New password: #输入hadoop后回车
BAD PASSWORD: The password is shorter than 8 characters
Retype new password: #再次输入hadoop后回车
passwd: all authentication tokens updated successfully.
[root@centos701 ~]# chown -R hadoop:hadoop /home/hadoop/
[root@centos701 ~]# chmod -R 755 /home/hadoop/
#把root用户的环境变量文件复制并覆盖hadoop用户下的.bash_profile
[root@centos701 ~]# cp .bash_profile /home/hadoop/
```
### 2.4 对hadoop用户做免密码登录
```
[hadoop@centos701 ~] su - hadoop
[hadoop@centos701 ~] source .bash_profile
#使用su - hadoop切换到hadoop用户下执行如下操作
[hadoop@centos701 ~]# ssh-keygen -t rsa  #<--回车
[hadoop@centos701 ~]# 
#修改.ssh目录权限
[hadoop@centos701 ~]$ chmod -R 755 .ssh/
[hadoop@centos701 ~]$ cd .ssh/
[hadoop@centos701 .ssh]$ chmod 644 *
[hadoop@centos701 .ssh]$ chmod 600 id_rsa
[hadoop@centos701 .ssh]$ chmod 600 id_rsa.pub 
[hadoop@centos701 .ssh]$
```

## 3.配置hadoop-env.sh、mapred-env.sh、yarn-env.sh
### 3.1 配置hadoop-env.sh
```
export JAVA_HOME=${JAVA_HOME} 修改成:
export JAVA_HOME=/opt/jdk
```
### 3.2 配置core-site.xml
- 设置 Hadoop 的临时目录和文件系统，localhost:9000 表示本地主机。在 core-site.xml 文件里作如下配置
```
<configuration>
   <property>
        <name>hadoop.tmp.dir</name>
        <value>/root/hadoop/tmp</value>
        <description>Abase for other temporary directories.</description>
   </property>
   <property>
        <name>fs.default.name</name>
        <value>hdfs://centos701:9000</value>
   </property>
</configuration>
```
### 3.3 配置hdfs-site.xml
- hdfs-site.xml 的配置修改如下，注意 name 和 data 的路径都要替换成本地的路径：
```
   <property>
     <name>dfs.name.dir</name>
     <value>/root/hadoop/dfs/name</value>
     <description>Path on the local filesystem where theNameNode stores the namespace and transactions logs persistently.</description>
   </property>
   <property>
     <name>dfs.data.dir</name>
     <value>/root/hadoop/dfs/data</value>
     <description>Comma separated list of paths on the localfilesystem of a DataNode where it should store its blocks.</description>
   </property>
   <property>
     <name>dfs.replication</name>
     <value>2</value>
   </property>
   <property>
     <name>dfs.permissions</name>
     <value>false</value>
     <description>need not permissions</description>
</property>
```
### 3.4 mapred-site.xml 文件
```
 <property>
     <name>mapred.job.tracker</name>
     <value>centos701:49001</value>
  </property>
  <property>
     <name>mapred.local.dir</name>
     <value>/root/hadoop/var</value>
  </property>
  <property>
     <name>mapreduce.framework.name</name>
     <value>yarn</value>
  </property>
```
### 3.5 yarn-site.xml 文件
```
<!-- Site specific YARN configuration properties -->
  <property>
       <name>yarn.resourcemanager.hostname</name>
       <value>centos701</value>
  </property>
  <property>
       <description>The address of the applications manager interface in the RM.</description>
       <name>yarn.resourcemanager.address</name>
       <value>${yarn.resourcemanager.hostname}:8032</value>
   </property>
   <property>
        <description>The address of the scheduler interface.</description>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>${yarn.resourcemanager.hostname}:8030</value>
   </property>
   <property>
        <description>The http address of the RM web application.</description>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>${yarn.resourcemanager.hostname}:8088</value>
   </property>
   <property>
        <description>The https adddress of the RM web application.</description>
        <name>yarn.resourcemanager.webapp.https.address</name>
        <value>${yarn.resourcemanager.hostname}:8090</value>
   </property>
   <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>${yarn.resourcemanager.hostname}:8031</value>
   </property>
   <property>
        <description>The address of the RM admin interface.</description>
        <name>yarn.resourcemanager.admin.address</name>
        <value>${yarn.resourcemanager.hostname}:8033</value>
   </property>
   <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
   </property>
   <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>2048</value>
        <discription>每个节点可用内存,单位MB,默认8182MB</discription>
   </property>
   <property>
        <name>yarn.nodemanager.vmem-pmem-ratio</name>
      	<value>2.1</value>
   </property>
   <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>2048</value>
   </property>
   <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
   </property>
```

### 3.6 配置 slaves
- vim /opt/hadoop-3.1.2/etc/hadoop/works
```
centos702
centos703
```
### 3.7 远程复制hadoop到集群机器
```
# 1.进入到root用户家目录下
[root@centos701 hadoop]# cd ~
# 2.使用scp远程拷贝命令将root用户的环境变量配置文件复制到centos702
[root@centos701 ~]# scp .bash_profile root@centos702:~  
# 3.使用scp远程拷贝命令将root用户的环境变量配置文件复制到centos703
[root@centos701 ~]# scp .bash_profile root@centos703:~   
# 4.进入到hadoop的share目录下
[root@centos701 ~]# cd /opt/bigdata/hadoop-3.1.2/share/
[root@centos701 share]# ll
# 5.删除doc目录,这个目录存放的是用户手册，比较大，等会儿下面进行远程复制的时候时间比较长，删除后节约复制时间
[root@centos701 share]# rm -rf doc/
[root@centos701 share]# cd ~
[root@centos701 ~]# scp -r /opt root@centos702:/
[root@centos701 ~]# scp -r /opt root@centos703:/
```

## 3.8 使集群所有机器环境变量生效  

在centos702，centos703的root用户家目录下使环境变量生效

centos702节点如下操作:
```shell
[root@centos702 hadoop-3.1.2]# cd ~
[root@centos702 ~]# source .bash_profile 
[root@centos702 ~]# hadoop version
```

centos703节点如下操作:
```shell
[root@centos703 bin]# cd ~
[root@centos703 ~]# source .bash_profile 
[root@centos703 ~]# hadoop version
```

# 3.9.修改hadoop安装目录的权限

centos702，centos703也需要进行如下操作

```shell
#1.修改目录所属用户和组为hadoop:hadoop
[root@centos701 ~]# chown -R hadoop:hadoop /opt/
#2.修改目录所属用户和组的权限值为755
[root@centos701 ~]# chmod -R 755  /opt/
[root@centos701 ~]# chmod -R g+w /opt/
[root@centos701 ~]# chmod -R o+w /opt/
```

## 4 启动集群
### 4.1 格式化hadoop
```
[root@centos701 ~]# su - hadoop
[hadoop@centos701 hadoop]$  hdfs namenode -format
```
### 4.2 启动集群
```
[hadoop@centos701 ~]$ start-all.sh 
[hadoop@centos701 ~]$ jps
21108 SecondaryNameNode
20792 NameNode
13420 Jps
21327 ResourceManager

[hadoop@centos702 bin]$ jps
74033 NodeManager
74146 Jps
73884 DataNode
```
### 4.3 停止集群
```
[hadoop@centos701 ~]$ stop-all.sh 
[hadoop@centos701 ~]$ jps 
```

## 5.访问hadoop
```
(1)输入命令，systemctl stop firewalld.service
(2)浏览器打开：http://172.16.232.130:9870
(3)浏览器打开：http://172.16.232.130:18088
```

## 6.使用hadoop

### 6.1 HDFS 中创建用户目录：
- hadoop fs
- hadoop dfs
- hdfs dfs
```
1. hadoop fs适用于任何不同的文件系统，比如本地文件系统和HDFS文件系统
2. hadoop dfs只能适用于HDFS文件系统
3. hdfs dfs跟hadoop dfs的命令作用一样，也只能适用于HDFS文件系统
```
```
> hdfs dfs -mkdir -p /user/hadoop
> hdfs dfs -ls /
```