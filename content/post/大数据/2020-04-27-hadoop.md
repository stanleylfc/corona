+++
title="hadoop 实战（一）| hadoop 安装"
tags=["hadoop"]
categories=["hadoop"]
date="2020-04-27T21:00:00+08:00"
+++
## 1.环境准备
### 1.1 服务器规划
```
# -u root -p centosdata 
172.16.232.130 centos701
172.16.232.131 centos702
172.16.232.132 centos703
```
### 1.2 关闭所有服务器的防火墙
```
systemctl stop firewalld.service # 停止firewall。
systemctl disable firewalld.service # 禁止firewall开机启动。
firewall-cmd --state # 查看默认防火墙装状态(关闭后显示notrunning, 开启显示running)。

ansible all -m shell -a 'firewall-cmd --state'
```
### 1.3 关闭服务器的SLNEX
```
vim /etc/selinux/config
SELINUX=disabled
```
### 1.4 配置时间同步
```
> yum install -y ntpdate
> crontab -e 
# 每分钟同步一次
*/1 * * * * /usr/sbin/ntpdate us.pool.ntp.org;

> date
```

### 1.5 安装网络工具net-tools
```
yum install -y net-tools
```

### 1.6 安装 java
```
rpm -ivh java-xxxx.rpm

/etc/profile  // 不建议配置在所有用户下
# java
export JAVA_HOME=/opt/jdk
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar

```
### 1.7 克隆虚拟机
```sh
# 关机重启
> init 0
```
#### 1.7.1 主机名和ip配置
#### 1.7.2 root用户免密码登录配置
```
[root@centos703 ~]# ssh-copy-id -i centos701
```

### 1.8 验证免密登录配置

此操作只在centos701上操作，其他机器上大家在验证。

```shell
#使用ssh 命令登录centos702
[root@centos701 ~]# ssh centos702
Last login: Sun Jun 30 13:56:53 2019 from centos701
#登录成功后这里的命令提示符已经变为[root@centos702 ~]#说明登录成功
[root@centos702 ~]# logout #退出centos702继续 验证登录centos703
Connection to centos702 closed.
#登录centos703
[root@centos701 ~]# ssh centos703
Last login: Sun Jun 30 13:56:55 2019 from centos701
#登录成功
[root@centos703 ~]# logout
Connection to centos703 closed.
You have new mail in /var/spool/mail/root
[root@centos701 ~]# 
```

### 1.9 添加本地认证公钥到认证文件中

```shell
#进入到root用户的家目录下
[root@centos701 ~]# cd ~
[root@centos701 ~]# cd .ssh/
#讲生成的公钥添加到认证文件中
[root@centos701 .ssh]# cat id_rsa.pub >> authorized_keys
[root@centos701 .ssh]# 
```



## 2.安装hadoop
- 存储和计算
- 批处理
- 流处理
### 2.1 hadoop解压后文件组织结构
- 下载地址：http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz
- tar -C /opt/ zxf hadoop-3.1.2.tar.gz
```
$ tree -L 1
├── bin
├── etc
├── include
├── lib
├── libexec
├── LICENSE.txt
├── logs
├── NOTICE.txt
├── README.txt
├── sbin
└── share
```
### 2.2 配置环境变量
```
# hadoop
export HADOOP_HOME=/opt/hadoop-3.1.2
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_COMMON_LIB_NATIVE_DIR"
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
### 2.3 创建hadoop 账户


## 3.配置hadoop-env.sh、mapred-env.sh、yarn-env.sh
### 3.1 配置hadoop-env.sh
```
export JAVA_HOME=${JAVA_HOME} 修改成:
export JAVA_HOME=/opt/jdk
```
### 3.2 配置core-site.xml
- 设置 Hadoop 的临时目录和文件系统，localhost:9000 表示本地主机。在 core-site.xml 文件里作如下配置
```
<configuration>
   <property>
        <name>hadoop.tmp.dir</name>
        <value>/root/hadoop/tmp</value>
        <description>Abase for other temporary directories.</description>
   </property>
   <property>
        <name>fs.default.name</name>
        <value>hdfs://centos701:9000</value>
   </property>
</configuration>
```
### 3.3 配置hdfs-site.xml
- hdfs-site.xml 的配置修改如下，注意 name 和 data 的路径都要替换成本地的路径：
```
   <property>
     <name>dfs.name.dir</name>
     <value>/root/hadoop/dfs/name</value>
     <description>Path on the local filesystem where theNameNode stores the namespace and transactions logs persistently.</description>
   </property>
   <property>
     <name>dfs.data.dir</name>
     <value>/root/hadoop/dfs/data</value>
     <description>Comma separated list of paths on the localfilesystem of a DataNode where it should store its blocks.</description>
   </property>
   <property>
     <name>dfs.replication</name>
     <value>2</value>
   </property>
   <property>
     <name>dfs.permissions</name>
     <value>false</value>
     <description>need not permissions</description>
</property>
```
### 3.4 mapred-site.xml 文件
```
 <property>
     <name>mapred.job.tracker</name>
     <value>centos701:49001</value>
  </property>
  <property>
     <name>mapred.local.dir</name>
     <value>/root/hadoop/var</value>
  </property>
  <property>
     <name>mapreduce.framework.name</name>
     <value>yarn</value>
  </property>
```
### 3.5 yarn-site.xml 文件
```
<!-- Site specific YARN configuration properties -->
  <property>
       <name>yarn.resourcemanager.hostname</name>
       <value>centos701</value>
  </property>
  <property>
       <description>The address of the applications manager interface in the RM.</description>
       <name>yarn.resourcemanager.address</name>
       <value>${yarn.resourcemanager.hostname}:8032</value>
   </property>
   <property>
        <description>The address of the scheduler interface.</description>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>${yarn.resourcemanager.hostname}:8030</value>
   </property>
   <property>
        <description>The http address of the RM web application.</description>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>${yarn.resourcemanager.hostname}:8088</value>
   </property>
   <property>
        <description>The https adddress of the RM web application.</description>
        <name>yarn.resourcemanager.webapp.https.address</name>
        <value>${yarn.resourcemanager.hostname}:8090</value>
   </property>
   <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>${yarn.resourcemanager.hostname}:8031</value>
   </property>
   <property>
        <description>The address of the RM admin interface.</description>
        <name>yarn.resourcemanager.admin.address</name>
        <value>${yarn.resourcemanager.hostname}:8033</value>
   </property>
   <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
   </property>
   <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>2048</value>
        <discription>每个节点可用内存,单位MB,默认8182MB</discription>
   </property>
   <property>
        <name>yarn.nodemanager.vmem-pmem-ratio</name>
      	<value>2.1</value>
   </property>
   <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>2048</value>
   </property>
   <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
   </property>
```

### 3.6 配置 slaves
- vim /opt/hadoop-3.1.2/etc/hadoop/works
```
centos702
centos703
```



## 4.启动hadoopp
```
(1)初始化，输入命令，bin/hdfs namenode -format
(2)全部启动sbin/start-all.sh
(3)停止的话，输入命令，sbin/stop-all.sh
(4)输入命令，jps，可以看到相关信息
```

## 5.访问hadoop
```
(1)输入命令，systemctl stop firewalld.service
(2)浏览器打开http://172.16.232.130:8088/
(3)浏览器打开http://172.16.232.130:50070/
```

## 6.使用hadoop

### 6.1 HDFS 中创建用户目录：
- hadoop fs
- hadoop dfs
- hdfs dfs
```
1. hadoop fs适用于任何不同的文件系统，比如本地文件系统和HDFS文件系统
2. hadoop dfs只能适用于HDFS文件系统
3. hdfs dfs跟hadoop dfs的命令作用一样，也只能适用于HDFS文件系统
```
```
> hdfs dfs -mkdir -p /user/hadoop
> 
```