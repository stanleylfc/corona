+++
title="大数据 实战（五）| spark 安装"
tags=["spark"]
categories=["大数据"]
date="2020-05-03T21:00:00+08:00"
+++
## 前期准备
- zookeeper集群

## 1. spark集群安装部署
### 1.1、下载安装包
- https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz
- spark-2.4.4-bin-hadoop2.7.tgz

### 1.2、规划安装目录
```
/opt/
```
### 1.3、上传安装包到服务器
### 1.4、解压安装包到指定的安装目录
- tar -zxvf  spark-2.4.4-bin-hadoop2.7.tgz  -C /opt
### 1.5、建立解压解压目录软连接
- ln -s  spark-2.4.4-bin-hadoop2.7  spark

### 1.6、修改配置文件
进入到spark的安装目录下对应的conf文件夹
- vim spark-env.sh ( mv spark-env.sh.template spark-env.sh)
```shell
#配置java的环境变量
export JAVA_HOME=/opt/jdk1.8.0_181
#配置zk相关信息
export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER  -Dspark.deploy.zookeeper.url=centos701:2181,node2:2181,node3:2181  -Dspark.deploy.zookeeper.dir=/spark"
```
- vim slaves ( mv slaves.template salves)
```
#指定spark集群的worker节点
centos702
centos703
```
### 1.7、分发安装目录到其他机器
```shell
scp -r spark centos702:/opt
scp -r spark centos703:/opt

ansible all -m copy -a "src=/opt/spark-2.4.4-bin-hadoop2.7 dest=/opt/spark-2.4.4-bin-hadoop27 owner=hadoop group=hadoop mode=0755"
```
### 1.8、修改spark环境变量
- vim /etc/profile
```shell
export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

SPARK_HOME=/opt/spark
PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export SPARK_HOME
```

### 1.9、分发spark环境变量到其他机器
```shell
scp /etc/profile centos702:/etc
scp /etc/profile centos703:/etc
```

### 1.10、让所有机器的spark环境变量生效
- 在所有节点执行
```
source /etc/profile
```

## 2. 启动和停止
### 2.1 启动
- 1、先启动zk
- 2、启动spark集群
```
# 可以在任意一台服务器来执行（条件：需要任意2台机器之间实现ssh免密登录）
$ SPARK_HOME/sbin/start-all.sh
# 在哪里启动这个脚本，就在当前该机器启动一个Master进程
# 整个集群的worker进程的启动由slaves文件
# 后期可以在其他机器单独在启动master
$ SPARK_HOME/sbin/start-master.sh
```
### 2.2 停止
在处于active Master主节点执行
```
$ SPARK_HOME/sbin/stop-all.sh
```
在处于standBy Master主节点执行
```
$ SPARK_HOME/sbin/stop-master.sh
```

### 3. 初识spark程序

#### 3.1 普通模式提交 (指定活着的master地址)

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://centos701:7077 \
--executor-memory 1G \
--total-executor-cores 2 \
examples/jars/spark-examples_2.11-2.4.4.jar \
10


####参数说明
--class：指定包含main方法的主类
--master：指定spark集群master地址
--executor-memory：指定任务在运行的时候需要的每一个executor内存大小
--total-executor-cores： 指定任务在运行的时候需要总的cpu核数

```

#### 3.2 高可用模式提交 (集群有很多个master）

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://centos701:7077,node2:7077,node3:7077 \
--executor-memory 1G \
--total-executor-cores 2 \
examples/jars/spark-examples_2.11-2.4.4.jar \
10

spark集群中有很多个master，并不知道哪一个master是活着的master，即使你知道哪一个master是活着的master，它也有可能下一秒就挂掉，这里就可以把所有master都罗列出来
--master spark://centos701:7077,node2:7077,node3:7077

后期程序会轮训整个master列表，最终找到活着的master，然后向它申请计算资源，最后运行程序。
```

## 4. spark-shell使用

### 4.1 运行spark-shell --master local[N] 读取本地文件进行单词统计

- --master local[N]

  - local 表示程序在本地进行计算，跟spark集群目前没有任何关系
  - N  它是一个正整数，表示使用N个线程参与任务计算
  - local[N] 表示本地采用N个线程计算任务

- spark-shell --master local[2]

  - 默认会产生一个SparkSubmit进程

  ```scala
  sc.textFile("file:///home/hadoop/words").flatMap(x=>x.split(" ")).map(x=>(x,1)).reduceByKey((x,y)=>x+y).collect
  
  sc.textFile("file:///home/hadoop/words.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect

  :quit
  ```

### 4.2 运行spark-shell --master local[N] 读取HDFS上文件进行单词统计

- spark整合HDFS
  - 在centos701上修改配置文件
    - vim spark-env.sh
  ```shell
  export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
  ```
  - 分发到其他节点
  ```shell
  scp spark-env.sh centos702:/opt/spark/conf
  scp spark-env.sh centos703:/opt/spark/conf
  ```
- spark-shell --master local[2]

  ```scala
  sc.textFile("/words.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect
  sc.textFile("hdfs://centos701:9000/words").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect
  ```

### 4.3 运行spark-shell 指定集群中活着master 读取HDFS上文件进行单词统计

- spark-shell --master spark://centos701:7077 --executor-memory 1g  --total-executor-cores 4

  - --master spark://centos701:7077
    - 指定活着的master地址
  - --executor-memory 1g
    - 指定每一个executor进程的内存大小
  - --total-executor-cores 4
    - 指定总的executor进程cpu核数

  ```scala
  sc.textFile("hdfs://centos701:9000/words").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect
  
  #实现读取hdfs上文件之后，需要把计算的结果保存到hdfs上
  sc.textFile("/words.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).saveAsTextFile("/out")
  ```
## 5. 通过IDEA开发spark程序